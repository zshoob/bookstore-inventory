{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scraper import *\n",
    "import itertools\n",
    "\n",
    "FIELD_MAP = {\n",
    "    'author': 'authors',\n",
    "    'isbn-13': 'isbn',\n",
    "    'format': 'format'\n",
    "}\n",
    "\n",
    "class EbayScraper(Scraper):\n",
    "    def __init__(self):\n",
    "        super(EbayScraper, self).__init__()\n",
    "        self.cache = {}\n",
    "    \n",
    "    def get(self, url, nocache=False):        \n",
    "        if isinstance(url, int) or re.match('\\d{12}', url):\n",
    "            url = 'http://www.ebay.com/itm/%s' % url\n",
    "        cached = not nocache and self.cache.get(url)\n",
    "        response = cached or requests.get(url)\n",
    "        if not nocache:\n",
    "            self.cache[url] = response\n",
    "        return response\n",
    "    \n",
    "    def read(self, page, listing_id=None, verbose=0):\n",
    "        listing_id = listing_id or int(re.search('itm[/=](\\d+)',page.url).group(1))\n",
    "        listing = html.fromstring(page.text)\n",
    "\n",
    "        category = re.findall(\"Books\\s?>\\s*(.*?)\\s*>\", read_text(listing))\n",
    "        \n",
    "        title_elem = listing.xpath('.//h1[@id=\"itemTitle\"]')[0]\n",
    "        title = clean_str(title_elem.text_content())\n",
    "        title = title.replace(u'Details about \\xa0', '')\n",
    "        \n",
    "        if verbose:\n",
    "            report('%s %s' % (listing_id, title))\n",
    "        price_elem = listing.xpath('.//span[@id=\"prcIsum\" or @id=\"prcIsum_bidPrice\"]')[0]\n",
    "        price = read_num(price_elem.text_content())\n",
    "        location_elem = listing.xpath('.//div[@id=\"itemLocation\"]')[0]\n",
    "        location = re.sub('[\\w ]+:', '', read_text(location_elem))\n",
    "        condition_elem = listing.xpath('.//div[@class=\"u-flL condText  \"]')[0]\n",
    "        condition = read_text(condition_elem)\n",
    "        \n",
    "        img_src = None\n",
    "        img_elem = listing.xpath('.//img[@id=\"icImg\"]')\n",
    "        if img_elem:\n",
    "            img_src = img_elem[0].get('src')\n",
    "        \n",
    "        data = {\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'location': location,\n",
    "            'condition': condition,\n",
    "            'category': category,\n",
    "            'image_source': img_src,\n",
    "            'updated': today().strftime(\"%Y-%m-%d %X\")\n",
    "        }\n",
    "        \n",
    "        specifics_data = []\n",
    "        specifics = listing.xpath('.//div[@class=\"itemAttr\"]')[0]\n",
    "        for key_elem in specifics.xpath('.//td[@class=\"attrLabels\"]'):\n",
    "            key = re.sub(':','', read_text(key_elem))\n",
    "            value = read_text(key_elem.getnext())\n",
    "            if clean_str(key).lower in FIELD_MAP:\n",
    "                data[FIELD_MAP[clean_str(key).lower()]] = value\n",
    "            data[key.lower()] = value\n",
    "            specifics_data.append(dict(listing_id=listing_id, key=key, value=value))\n",
    "        data['specifics'] = specifics_data\n",
    "\n",
    "        shipping_costs = [read_num(read_text(span)) or 0.0 for span in listing.xpath('.//span[@id=\"fshippingCost\"]')]\n",
    "        shipping_types = [read_text(span) for span in listing.xpath('.//span[@id=\"fshippingSvc\"]')]\n",
    "        shipping_data = [dict(listing_id=listing_id, cost=cost, kind=kind) for cost, kind in zip(shipping_costs, shipping_types)]\n",
    "        data['shipping'] = shipping_data\n",
    "            \n",
    "        detailed_data = []\n",
    "        detailed = listing.xpath(\".//div[@class='prodDetailDesc']\")\n",
    "        if detailed:\n",
    "            detailed = detailed[0]\n",
    "            pairs = []\n",
    "            category = ''\n",
    "            for row in detailed.xpath(\".//tr\"):\n",
    "                cat_elem = row.xpath(\"./td/font/b\")\n",
    "                if cat_elem:\n",
    "                    category = clean_str(cat_elem[0].text_content())\n",
    "                elif category > '':\n",
    "                    tds = [clean_str(td.text_content()) for td in row.xpath(\"./td\")]\n",
    "                    if len(tds) == 2:\n",
    "                        k, v = [clean_str(td.text_content()) for td in row.xpath(\"./td\")]\n",
    "                    else:\n",
    "                        k, v = category, tds[0]\n",
    "                    if clean_str(key).lower in FIELD_MAP:\n",
    "                        data[FIELD_MAP[clean_str(key).lower()]] = value\n",
    "                    data[k.lower()] = v\n",
    "        data['detailed'] = detailed_data\n",
    "                        \n",
    "        return data\n",
    "    \n",
    "    def scrape(self, listing_id):\n",
    "        return self.read(self.get(listing_id))\n",
    "    \n",
    "def scrape(listing_id):\n",
    "    return EbayScraper().scrape(listing_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
